\section{Our approach - preprocessing and algorithms} %How will you solve the problem
\label{cha:approach}
%\textbf{Integration of JSON data}: 
As the source format of the data is JSON, we have transform it into a format RapidMiner can process. We've looked at two options:\\
RapidMiner offers an operator "JSON to data" to transform a set of JSON documents into an example set. With further transformation steps (e.g.transposing columns into rows, transforming the array dimensions into separate columns%using regular expressions
), the data can be transformed into a tabular structure. However, the mentionend Operator expects an array of JSON documents or separate files for each object%in order to create the correct structure. 
, but the given dataset only contains single files with all objects concatenated, not collected in an array. Thus, using RapidMiner for the JSON transformation would require another workaround to transform the files into the needed input structure.\\ % preprocessing of the provided files necessary: Either splitting them into separate files for each JSON object (per type), or transforming the object type files into an array of all objects.\\
The second option is to directly transform the existing JSON files into a format RapidMiner can work with, using external tools. In their github repository %(\url{https://github.com/Yelp/dataset-examples})
, contributers have already provided scripts that execute JSON to csv conversion, based on which we can transform the given dataset. %Challenge size of dataset? 

- As a first step we will filter the businesses to look at during the process-building-phase. The processing steps will take too long to apply to the entire dataset several times from the start. we will begin by sampling a rather small but still representative subset of the data to work on. This dataset will contain businesses meta data and textual reviews for around 50 businesses. We will also extract the reviews of 10 businesses as our validation set and another 10 as our test set. When sampling the data we will make sure to include businesses that have positive overall ratings and also businesses with negative overall ratings to create a balanced dataset. Both the validation and test set will need manual evaluation of the sentiments for the different aspects mentioned in the reviews. Thus we will only include businesses in the validation and test set that have a manageable amount of reviews. \\
- Once we have the data sampled we will extract the reviews for each business and create a concatenated version of them in a single document. We do not need the information which sentences originated from which review since we want to look at the entire set of reviews to extract new attributes for the business.\\
- At this stage we will proceed with common text preprocessing methods. Those will include tokenization, stop-word removal and POS tagging. We will follow with our approach a method published by Bancken, Alfarone and Davis in "`Automatically Detecting and Rating Product Aspects from Textual Customer Reviews'". We will make use of the Stanford CoreNLP to apply the preprocessing steps and extract syntactical dependencies on a per sentence base. \\
- The next step will be to build an algorithm that is able to extract the relevant syntactical dependencies identified by the Stanford Parser. We will build on the relevant dependencies identified in the paper by Bancken, Alfarone and Davis. The result of this preprocessing step are tuples in the form <sentiment modifier, potential aspect>. \\
- After that we will apply a clustering algorithm (k-means or k-medoids) to cluster tuples together that express a sentiment for the same aspect. To accomplish this we will use a Word-net based similarity metric calles Jcn. An implementation of this metric can be found in the WS4J library. The similarity metric will be calculated for each pair of potential aspects after they were stemmed to reduce the number of different words. The metric will then serve as input to a clustering algorithm which will output clusters that represent different aspects. As a result of this step we can reduce the number of potential aspects to increase our precision based on the cluster-size.\\
- Afterwards we will make us of a sentiment lexicon for the English language to determine sentiment values for the sentiment modifiers identified in a previous step. As a result we will be able to assign sentiment values to aspect-clusters which were identified in the previous step. We will then extract the most positive and the most negative aspects which form our result.